{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill out the information of your group!\n",
    "\n",
    "| <p style=\"text-align: center;\">First Name</p>  | <p style=\"text-align: center;\">Family Name</p> | Matr.-No. |\n",
    "| ---------------------------------------------- | ---------------------------------------------- | -------- |\n",
    "| <p style=\"text-align: left\">Branko</p>        | <p style=\"text-align: left\">Paunović</p>       | <p>k12046370</p> |\n",
    "| <p style=\"text-align: left\">Vladyslav</p>     | <p style=\"text-align: left\">Savchenko</p>      | <p>k12227285</p> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\">344.105/6/7 UE: Natural Language Processing (WS2023/24)</h2>\n",
    "<h1 style=\"color:rgb(0,120,170)\">Assignment 2</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\">Getting to Know Word Embedding!</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Terms of Use</b><br>\n",
    "This  material is prepared for educational purposes at the Johannes Kepler University (JKU) Linz, and is exclusively provided to the registered students of the mentioned course at JKU. It is strictly forbidden to distribute the current file, the contents of the assignment, and its solution. The use or reproduction of this manuscript is only allowed for educational purposes in non-profit organizations, while in this case, the explicit prior acceptance of the author(s) is required.\n",
    "\n",
    "**Authors:** Navid Rekab-saz, Oleg Lesota<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of contents</h2>\n",
    "<ol>\n",
    "    <a href=\"#section-general-guidelines\"><li style=\"font-size:large;font-weight:bold\">General Guidelines</li></a>\n",
    "    <a href=\"#section-taskA\"><li style=\"font-size:large;font-weight:bold\">Task A: Words Similarity and Nearest Neighbors (15 points)</li></a>\n",
    "    <a href=\"#section-taskB\"><li style=\"font-size:large;font-weight:bold\">Task B: Document Classification with Word Embedding (15 points)</li></a>\n",
    "    <a href=\"#section-taskC\"><li style=\"font-size:large;font-weight:bold\">Task C: Classification with sent2vec Document Embeddings (2 extra point)</li></a>\n",
    "    <a href=\"#section-references\"><li style=\"font-size:large;font-weight:bold\">References</li></a>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-general-guidelines\"></a><h2 style=\"color:rgb(0,120,170)\">General Guidelines</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment objective\n",
    "The aim of this assignment is to get familiarized with using word embedding (WE) models in practice. The assignment in total has **30 points**; it also offers **2 extra points** which can cover any missing point.\n",
    "\n",
    "This Notebook encompasses all aspects of the assignment, namely the descriptions of tasks as well as your solutions and reports. Feel free to add any required cell for solutions. The cells can contain code, reports, charts, tables, or any other material, required for the assignment. Feel free to provide the solutions in an interactive and visual way! \n",
    "\n",
    "Please discuss any unclear point in the assignment in the provided forum in MOODLE. It is also encouraged to provide answers to your peer's questions. However when submitting a post, keep in mind to avoid providing solutions. Please let the tutor(s) know shall you find any error or unclarity in the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries & Dataset\n",
    "\n",
    "The assignment should be implemented with recent versions of `Python` (>3.7). Any standard Python library can be used, so far that the library is free and can be simply installed using `pip` or `conda`. Examples of potentially useful libraries are `scikit-learn`, `numpy`, `scipy`, `gensim`, `nltk`, `spaCy`, and `AllenNLP`. Use the latest stable version of each library.\n",
    "\n",
    "To conduct the experiments, we use a subset of the `HumSet` dataset [1] (https://blog.thedeep.io/humset/). `HumSet` is created by the DEEP (https://www.thedeep.io) project – an open source platform which aims to facilitate processing of textual data for international humanitarian response organizations. The platform enables the classification of text excerpts, extracted from news and reports into a set of domain specific classes. The provided dataset contains the classes (labels) referring to the humanitarian sectors like agriculture, health, and protection. The dataset contains an overall number of 17,301 data points. \n",
    "\n",
    "Download the dataset from the Moodle page of the course.\n",
    "\n",
    "the provided zip file consists of the following files:\n",
    "- `thedeep.subset.train.txt`: Train set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.validation.txt`: Validation set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.test.txt`: Test set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.label.txt`: Captions of the labels.\n",
    "- `thedeep.ToU.txt`: Terms of use of the dataset.\n",
    "\n",
    "[1] HumSet: Dataset of Multilingual Information Extraction and Classification for Humanitarian Crises Response\n",
    "*Selim Fekih, Nicolo' Tamagnone, Benjamin Minixhofer, Ranjan Shrestha, Ximena Contla, Ewan Oglethorpe and Navid Rekabsaz.* \n",
    "In Findings of the 2022 Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP), December 2022.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Submission\n",
    "\n",
    "Each group should submit the following two files:\n",
    "\n",
    "- One Jupyter Notebook file (`.ipynb`), containing all the code, results, visualizations, etc. **In the submitted Notebook, all the results and visualizations should already be present, and can be observed simply by loading the Notebook in a browser.** The Notebook must be self-contained, meaning that (if necessary) one can run all the cells from top to bottom without any error. Do not forget to put in your names and student numbers in the first cell of the Notebook. \n",
    "- The HTML file (`.html`) achieved from exporting the Jupyter Notebook to HTML (Download As HTML).\n",
    "\n",
    "You do not need to include the data files in the submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-taskA\"></a><h2 style=\"color:rgb(0,120,170)\">Task A: Words Similarity and Nearest Neighbors (15 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Loading a word embedding (WE) model (1 points).** Download a pre-trained word embedding model such as word2vec (https://code.google.com/archive/p/word2vec/) or GloVe (https://nlp.stanford.edu/projects/glove/). You can load the downloaded vectors into arrays, or use libraries such as `gensim` to download and process the vectors. \n",
    "\n",
    "**Calculating word-to-word similarities (4 points).** Select <ins>5 arbitrary words</ins> from 5 different topics like objects, science disciplines, verbs, adjectives, animals, etc. Let us refer to these words as *source words*. For each source word, calculate its cosine similarities to <ins>6 target words</ins>. The target words of each source word are also selected by you and should cover various levels of semantic relations – according to your linguistic judgement – to the source word, namely from highly-related to not related at all. Organize the target words in tables, such that the target words of each source word are sorted from the highest to the lowest relevance (according to your judgement). Consider the following points:\n",
    "\n",
    "- **Implementation (2/4 points):** Implement cosine similarity as a function that takes two vectors and returns the similarity score. Implement cosine by yourself and do NOT use the provided functionalities of any library.\n",
    "- **Reporting and observations (2/4 points):** Report the calculated similarities side by side with your word-to-word semantic relevance judgements in tables. Compare the results and report your observations.  \n",
    "\n",
    "**Calculating nearest neighbors (10 points).** For the 5 source words, retrieve the $k=10$ nearest neighbors using the word embedding model, namely the words with the highest similarities to the source word. Consider the following points: \n",
    "    \n",
    "- **Overall implementation (3/10 points):** your implemented function takes a source vector, a set of target vectors, and the $k$ parameter, and returns the $k$ nearest neighbors and their similarity scores. Implement nearest neighbor calculation by yourself and do NOT use the provided functionalities of any library.\n",
    "- **Similarity metrics (2/10 points):** execute the calculation of nearest neighbors according to <ins>two similarity metrics</ins> namely cosine and dot product.\n",
    "- **Efficiency (3/10 points):** your nearest neighbor functions should provide an *efficient* calculation of nearest neighbors. An inefficient way (which should be avoided!) would be looping over the set of vectors in the word embedding model, and one by one calculating the cosine/dot product similarity of the source vector to each of the target vectors. As a hint for an efficient way, consider that in `numpy` (and other libraries), calculating the dot product of a vector to a matrix is much faster than the dot products of the vector to each vector of the matrix.\n",
    "- **Reporting and observations (2/10 points):** report the results in tables, which enable comparing between the outputs of the two similarity metrics. Which similarity metric would you prefer? Report your observations.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a word embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(glove_file):\n",
    "    \"\"\"\n",
    "    :param glove_file: embeddings_path: path of glove file.\n",
    "    :return: glove model\n",
    "    \"\"\"\n",
    "\n",
    "    f = open(glove_file + \".txt\", 'r', encoding='utf-8')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        split_line = line.split()\n",
    "        word = split_line[0]\n",
    "        embedding = np.array([float(val) for val in split_line[1:]])\n",
    "        model[word] = embedding\n",
    "    f.close()\n",
    "    return model\n",
    "\n",
    "model = load_glove_model(\"glove.6B.100d\")\n",
    "# here we have 400k words as embedings, pretrained with GloVe model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating word-to-word similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now choose some words, like: cat, triangle, smart, blue and flying<br>\n",
    "As tagets words use:<br>\n",
    "For cat: animal, dog, tail, domesticated, routine, diverges <br>\n",
    "For triangle: polygon, geometry, pyramids\", sharp, egypt, penta <br>\n",
    "For smart: clever, phone, pet, scientist, gum, anarchy <br>\n",
    "For blue: color, red, ocean, france, sadness, delaying <br>\n",
    "For flying: plane, sky, star, leaf, penguin, recursive <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cos(x, y):\n",
    "    \"\"\"\n",
    "    Compute cos(x, y) where x, y are vectors (embeddings)\n",
    "    :param x: first vector\n",
    "    :param y: second vector\n",
    "    :return: distance between given x and y\n",
    "    \"\"\"\n",
    "    xy_dot_prod = 0\n",
    "    for i in range(x.size):\n",
    "        xy_dot_prod += x[i]*y[i]\n",
    "    x_two_norm = np.linalg.norm(x)\n",
    "    y_two_norm = np.linalg.norm(y)\n",
    "    return xy_dot_prod / (x_two_norm * y_two_norm)\n",
    "\n",
    "def display_word_target_cos(word, targets):\n",
    "    \"\"\"\n",
    "    Display similarity between two words:\n",
    "    :param word: given word, the targets are compared to\n",
    "    :targets: array of target words\n",
    "    :return: -\n",
    "    \"\"\"\n",
    "    for target in targets:\n",
    "        print(f\"{word} and {target} similarity score:\", compute_cos(model.get(word), model.get(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "cat and animal similarity score: 0.6200780789843513\n",
      "cat and dog similarity score: 0.8798075041293155\n",
      "cat and tail similarity score: 0.498913568097558\n",
      "cat and domesticated similarity score: 0.37443498622822186\n",
      "cat and routine similarity score: 0.282175848392274\n",
      "cat and diverges similarity score: 0.0045659344322218675\n",
      "------------------------------------------------------------------------------------------------------\n",
      "triangle and polygon similarity score: 0.4187617562438889\n",
      "triangle and geometry similarity score: 0.35469458466248005\n",
      "triangle and pyramids similarity score: 0.2920967194861111\n",
      "triangle and sharp similarity score: 0.2135364739664046\n",
      "triangle and egypt similarity score: 0.18267866148186557\n",
      "triangle and penta similarity score: -0.14578928331081956\n",
      "------------------------------------------------------------------------------------------------------\n",
      "smart and clever similarity score: 0.6687245100293685\n",
      "smart and phone similarity score: 0.5439341975501654\n",
      "smart and pet similarity score: 0.3754460769922143\n",
      "smart and scientist similarity score: 0.2519682703952896\n",
      "smart and gum similarity score: 0.1504512064779037\n",
      "smart and anarchy similarity score: -0.018550342385141444\n",
      "------------------------------------------------------------------------------------------------------\n",
      "blue and color similarity score: 0.6302878504287791\n",
      "blue and red similarity score: 0.8435065112059561\n",
      "blue and ocean similarity score: 0.38892435824288496\n",
      "blue and france similarity score: 0.29150626116241607\n",
      "blue and sadness similarity score: 0.11676500705412202\n",
      "blue and delaying similarity score: -0.04925750974405576\n",
      "------------------------------------------------------------------------------------------------------\n",
      "flying and plane similarity score: 0.7532853261398603\n",
      "flying and sky similarity score: 0.5464181705324506\n",
      "flying and star similarity score: 0.400613430116426\n",
      "flying and leaf similarity score: 0.28340606352194303\n",
      "flying and penguin similarity score: 0.1549805387720023\n",
      "flying and recursive similarity score: 0.01766230750475759\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "cat_targets = [\"animal\", \"dog\", \"tail\", \"domesticated\", \"routine\", \"diverges\"]\n",
    "display_word_target_cos(\"cat\", cat_targets)\n",
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "triangle_targets = [\"polygon\", \"geometry\", \"pyramids\", \"sharp\", \"egypt\", \"penta\"]\n",
    "display_word_target_cos(\"triangle\", triangle_targets)\n",
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "smart_targets = [\"clever\", \"phone\", \"pet\", \"scientist\", \"gum\", \"anarchy\"]\n",
    "display_word_target_cos(\"smart\", smart_targets)\n",
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "blue_targets = [\"color\", \"red\", \"ocean\", \"france\", \"sadness\", \"delaying\"]\n",
    "display_word_target_cos(\"blue\", blue_targets)\n",
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "flying_targets = [\"plane\", \"sky\", \"star\", \"leaf\", \"penguin\", \"recursive\"]\n",
    "display_word_target_cos(\"flying\", flying_targets)\n",
    "print(\"------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting and observations\n",
    "As expected, the more semantically \"closer\" target words, the more score they achieve by cosine function. Almost all semantical predictions are ranked by cos as expected. However we made a small mistake, when general catagories were ranked above \"similar\" words. E.g.:blue and red have more semantic relations in comarison to blue and color. But generally semantical similarity has reasonable corelation the score. <br>\n",
    "The tables for \"blue\" and \"cat\", since other words have the same ranking: <br>\n",
    "color\", \"red\", \"ocean\", \"france\", \"sadness\", \"delaying\n",
    "#### For \"cat\":\n",
    "| rank | Manually constructed  | By cos score |\n",
    "| :- | -: | :-: |\n",
    "| 1 | animal | dog\n",
    "| 2 | dog | animal \n",
    "| 3 | tail | tail\n",
    "| 4 | domesticated | domesticated\n",
    "| 5 | routine | routine\n",
    "| 6 | diverges | diverges\n",
    "#### For \"blue\":\n",
    "| rank | Manually constructed  | By cos score |\n",
    "| :- | -: | :-: |\n",
    "| 1 | color | red\n",
    "| 2 | red | color \n",
    "| 3 | ocean | ocean\n",
    "| 4 | france | france\n",
    "| 5 | sadness | sadness\n",
    "| 6 | delaying | delaying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 100)\n"
     ]
    }
   ],
   "source": [
    "# to be honest I think vect_length shold be hardcoded, but anyway let it be like this for now \n",
    "vect_length = model.get(list(model.keys())[0]).size\n",
    "\n",
    "id_word = {}\n",
    "# matrix, where each row is represented by word and \n",
    "words_matrix = np.zeros((len(model),vect_length))\n",
    "for i, word in enumerate(model):\n",
    "    id_word[i] = word\n",
    "    words_matrix[i] = model.get(word)\n",
    "print(words_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD:  cat -----------------------------------------------------------------------------\n",
      "\n",
      "Using cos function:\n",
      "cat and dog has similarity: 0.8798\n",
      "cat and rabbit has similarity: 0.7424\n",
      "cat and cats has similarity: 0.7323\n",
      "cat and monkey has similarity: 0.7289\n",
      "cat and pet has similarity: 0.7190\n",
      "cat and dogs has similarity: 0.7164\n",
      "cat and mouse has similarity: 0.6915\n",
      "cat and puppy has similarity: 0.6800\n",
      "cat and rat has similarity: 0.6641\n",
      "cat and spider has similarity: 0.6501\n",
      "\n",
      "Using dot product:\n",
      "cat and dog has similarity: 24.9974\n",
      "cat and dogs has similarity: 20.3302\n",
      "cat and pet has similarity: 19.7467\n",
      "cat and mouse has similarity: 19.4296\n",
      "cat and rabbit has similarity: 19.1802\n",
      "cat and monkey has similarity: 18.8589\n",
      "cat and cats has similarity: 18.6155\n",
      "cat and bird has similarity: 18.5562\n",
      "cat and baby has similarity: 18.3632\n",
      "cat and horse has similarity: 18.1018\n",
      "WORD:  triangle -----------------------------------------------------------------------------\n",
      "\n",
      "Using cos function:\n",
      "triangle and equilateral has similarity: 0.5825\n",
      "triangle and loop has similarity: 0.5716\n",
      "triangle and circle has similarity: 0.5570\n",
      "triangle and triangles has similarity: 0.5476\n",
      "triangle and ring has similarity: 0.5245\n",
      "triangle and axis has similarity: 0.5126\n",
      "triangle and triangular has similarity: 0.5064\n",
      "triangle and hypotenuse has similarity: 0.5061\n",
      "triangle and angle has similarity: 0.5053\n",
      "triangle and outer has similarity: 0.5036\n",
      "\n",
      "Using dot product:\n",
      "triangle and equilateral has similarity: 16.8406\n",
      "triangle and loop has similarity: 15.8079\n",
      "triangle and axis has similarity: 15.6629\n",
      "triangle and triangular has similarity: 15.0958\n",
      "triangle and triangles has similarity: 14.9625\n",
      "triangle and vertices has similarity: 14.7652\n",
      "triangle and angle has similarity: 14.5943\n",
      "triangle and ring has similarity: 14.3210\n",
      "triangle and junction has similarity: 14.3126\n",
      "triangle and outer has similarity: 14.3035\n",
      "WORD:  smart -----------------------------------------------------------------------------\n",
      "\n",
      "Using cos function:\n",
      "smart and intelligent has similarity: 0.7553\n",
      "smart and sophisticated has similarity: 0.6903\n",
      "smart and clever has similarity: 0.6687\n",
      "smart and pretty has similarity: 0.6568\n",
      "smart and kind has similarity: 0.6472\n",
      "smart and really has similarity: 0.6461\n",
      "smart and incredibly has similarity: 0.6443\n",
      "smart and savvy has similarity: 0.6280\n",
      "smart and better has similarity: 0.6279\n",
      "smart and good has similarity: 0.6261\n",
      "\n",
      "Using dot product:\n",
      "smart and intelligent has similarity: 19.9191\n",
      "smart and you has similarity: 19.4773\n",
      "smart and sophisticated has similarity: 19.2363\n",
      "smart and really has similarity: 19.0290\n",
      "smart and i has similarity: 18.9315\n",
      "smart and funny has similarity: 18.7606\n",
      "smart and 're has similarity: 18.5379\n",
      "smart and 'm has similarity: 18.2884\n",
      "smart and pretty has similarity: 18.2542\n",
      "smart and good has similarity: 18.1636\n",
      "WORD:  blue -----------------------------------------------------------------------------\n",
      "\n",
      "Using cos function:\n",
      "blue and red has similarity: 0.8435\n",
      "blue and black has similarity: 0.8066\n",
      "blue and pink has similarity: 0.7868\n",
      "blue and green has similarity: 0.7868\n",
      "blue and purple has similarity: 0.7847\n",
      "blue and yellow has similarity: 0.7777\n",
      "blue and gray has similarity: 0.7732\n",
      "blue and bright has similarity: 0.7431\n",
      "blue and white has similarity: 0.7365\n",
      "blue and dark has similarity: 0.7170\n",
      "\n",
      "Using dot product:\n",
      "blue and red has similarity: 29.5000\n",
      "blue and black has similarity: 28.4665\n",
      "blue and white has similarity: 27.1514\n",
      "blue and green has similarity: 26.8947\n",
      "blue and yellow has similarity: 26.7866\n",
      "blue and pink has similarity: 26.1560\n",
      "blue and dark has similarity: 24.8052\n",
      "blue and purple has similarity: 24.5768\n",
      "blue and bright has similarity: 23.7360\n",
      "blue and gray has similarity: 23.4145\n",
      "WORD:  flying -----------------------------------------------------------------------------\n",
      "\n",
      "Using cos function:\n",
      "flying and flew has similarity: 0.7707\n",
      "flying and fly has similarity: 0.7651\n",
      "flying and planes has similarity: 0.7625\n",
      "flying and jet has similarity: 0.7616\n",
      "flying and aircraft has similarity: 0.7613\n",
      "flying and plane has similarity: 0.7533\n",
      "flying and flight has similarity: 0.7430\n",
      "flying and airplane has similarity: 0.7300\n",
      "flying and airplanes has similarity: 0.7134\n",
      "flying and air has similarity: 0.7094\n",
      "\n",
      "Using dot product:\n",
      "flying and aircraft has similarity: 27.7549\n",
      "flying and plane has similarity: 26.2015\n",
      "flying and planes has similarity: 26.0612\n",
      "flying and flight has similarity: 25.5058\n",
      "flying and air has similarity: 24.3543\n",
      "flying and jet has similarity: 24.1254\n",
      "flying and fly has similarity: 23.0670\n",
      "flying and helicopter has similarity: 22.7373\n",
      "flying and flights has similarity: 22.5178\n",
      "flying and helicopters has similarity: 21.8078\n"
     ]
    }
   ],
   "source": [
    "def efficient_top_k_nearest_neighbors_cos(word, words_matrix, model, k):\n",
    "    \"\"\"\n",
    "    Finds top 10 words with highest score with cos function\n",
    "    :param word: the word, k nearest neighbors shuld be found\n",
    "    :param words_matrix: matrix of words x embeddings \n",
    "    :param model: model to map the word \n",
    "    :param model: model to map the word \n",
    "    :return: list of tuples (word, score), where word with the greatest score goes first and score decreases over iterations\n",
    "    \"\"\"\n",
    "    word_embedding = model.get(word)\n",
    "    # single value 2 norm of word \n",
    "    x_euclidean_norm = np.linalg.norm(word_embedding)\n",
    "    # vector of length equal to length of dictionary of model with 2 norms\n",
    "    y_euclidean_norms = np.linalg.norm(words_matrix, axis = 1)\n",
    "    # substitute to cos function\n",
    "    result_matrix = words_matrix.dot(word_embedding) / (x_euclidean_norm * y_euclidean_norms)\n",
    "    # we doesn't need last elem, since it is word itself\n",
    "    top_indices = np.argsort(result_matrix)[-(k+1):-1][::-1]\n",
    "    result = []\n",
    "    for i, ind in enumerate(top_indices):\n",
    "        result.append((id_word.get(ind), result_matrix[ind]))\n",
    "    return result\n",
    "\n",
    "def efficient_top_k_nearest_neighbors_dot_prod(word, words_matrix, model, k):\n",
    "    \"\"\"\n",
    "    Finds top 10 words with highest score with dot product only\n",
    "    :param word: the word, k nearest neighbors shuld be found\n",
    "    :param words_matrix: matrix of words x embeddings \n",
    "    :param model: model to map the word \n",
    "    :param model: model to map the word \n",
    "    :return: list of tuples (word, score), where word with the greatest score goes first and score decreases over iterations\n",
    "    \"\"\"\n",
    "    word_embedding = model.get(word)\n",
    "    # single value 2 norm of word \n",
    "    result_matrix = words_matrix.dot(word_embedding) \n",
    "    # we doesn't need last elem, since it is word itself\n",
    "    top_indices = np.argsort(result_matrix)[-(k+1):-1][::-1]\n",
    "    result = []\n",
    "    for i, ind in enumerate(top_indices):\n",
    "        result.append((id_word.get(ind), result_matrix[ind]))\n",
    "    return result\n",
    "\n",
    "k = 10\n",
    "words = [\"cat\", \"triangle\", \"smart\", \"blue\", \"flying\"]\n",
    "for word in words:\n",
    "    print(\"WORD: \", word, \"-----------------------------------------------------------------------------\")\n",
    "    top_k_cos = efficient_top_k_nearest_neighbors_cos(word, words_matrix, model, k)\n",
    "    top_k_dotprod = efficient_top_k_nearest_neighbors_dot_prod(word, words_matrix, model, k)\n",
    "    print(\"\\nUsing cos function:\")\n",
    "    for word_in_k, score in top_k_cos: \n",
    "        print(f\"{word} and {word_in_k} has similarity: {score:.4f}\")\n",
    "    print(\"\\nUsing dot product:\")\n",
    "    for word_in_k, score in top_k_dotprod: \n",
    "        print(f\"{word} and {word_in_k} has similarity: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting and observations\n",
    "### Draw comparison tables for easier readability\n",
    "#### For cat:\n",
    "| rank | cos ranked | cos score | dot product ranked | dot product score \n",
    "| --- | --- | --- | --- | ---\n",
    "| 1 | dog | 0.8798 | dog | 24.9974\n",
    "| 2 | rabbit | 0.7424 | dogs | 20.3302\n",
    "| 3 | cats | 0.7323 | pet | 19.7467\n",
    "| 4 | monkey | 0.7289 | mouse | 19.4296\n",
    "| 5 | pet | 0.7190 | rabbit | 19.1802\n",
    "| 6 | dogs | 0.7164 |  monkey | 18.8589\n",
    "| 7 | mouse | 0.6915 | cats | 18.6155\n",
    "| 8 | puppy | 0.6800 | bird | 18.5562\n",
    "| 9 | rat | 0.6641 | baby | 18.3632\n",
    "| 10 | spider | 0.6501 | horse | 18.1018\n",
    "\n",
    "#### For triangle:\n",
    "| rank | cos ranked | cos score | dot product ranked | dot product score \n",
    "| --- | --- | --- | --- | ---\n",
    "| 1 | equilateral | 0.5825 | equilateral | 16.8406\n",
    "| 2 | loop | 0.5716 | loop | 15.8079\n",
    "| 3 | circle | 0.5570 | axis | 15.6629\n",
    "| 4 | triangles | 0.5476 | triangular | 15.0958\n",
    "| 5 | ring | 0.5245 | triangles | 14.9625\n",
    "| 6 | axis | 0.5126 |  vertices | 14.7652\n",
    "| 7 | triangular | 0.5064 | angle | 14.5943\n",
    "| 8 | hypotenuse | 0.5061 | ring | 14.3210\n",
    "| 9 | angle | 0.5053 | junction | 14.3126\n",
    "| 10 | outer | 0.5036 | outer | 14.3035\n",
    "\n",
    "#### For smart:\n",
    "| rank | cos ranked | cos score | dot product ranked | dot product score \n",
    "| --- | --- | --- | --- | ---\n",
    "| 1 | intelligent | 0.7553 | intelligent | 19.9191\n",
    "| 2 | sophisticated | 0.6903 | you | 19.4773\n",
    "| 3 | clever | 0.6687 | sophisticated | 19.2363\n",
    "| 4 | pretty | 0.6568 | really | 19.0290\n",
    "| 5 | kind | 0.6472 | i | 18.9315\n",
    "| 6 | really | 0.6461 |  funny | 18.7606\n",
    "| 7 | incredibly | 0.6443 | 're | 18.5379\n",
    "| 8 | savvy | 0.6280 | 'm | 18.2884\n",
    "| 9 | better | 0.6279 | pretty | 18.2542\n",
    "| 10 | good | 0.6261 | good | 18.1636\n",
    "\n",
    "#### For blue:\n",
    "| rank | cos ranked | cos score | dot product ranked | dot product score \n",
    "| --- | --- | --- | --- | ---\n",
    "| 1 | red | 0.8435 | red | 29.5000\n",
    "| 2 | black | 0.8066 | black | 28.4665\n",
    "| 3 | pink | 0.7868 | white | 27.1514\n",
    "| 4 | green | 0.7868 | green | 26.8947\n",
    "| 5 | purple |  0.7847 | yellow | 26.7866\n",
    "| 6 | yellow | 0.7777 |  pink | 26.1560\n",
    "| 7 | gray | 0.7732 | dark | 24.8052\n",
    "| 8 | bright | 0.7431 | purple | 24.5768\n",
    "| 9 | white | 0.7365 | bright | 23.7360\n",
    "| 10 | dark | 0.7170 | gray | 23.4145\n",
    "\n",
    "#### For flying:\n",
    "| rank | cos ranked | cos score | dot product ranked | dot product score \n",
    "| --- | --- | --- | --- | ---\n",
    "| 1 | flew | 0.7707 | aircraft | 27.7549\n",
    "| 2 | fly | 0.7651 | plane | 26.2015\n",
    "| 3 | planes | 0.7625 | planes | 26.0612\n",
    "| 4 | jet | 0.7616 | flight | 25.5058\n",
    "| 5 | aircraft |  0.7613 | air | 24.3543\n",
    "| 6 | plane | 0.7533 |  jet | 24.1254\n",
    "| 7 | flight | 0.7430 | fly | 23.0670\n",
    "| 8 | airplane | 0.7300 | helicopter | 22.7373\n",
    "| 9 | airplanes | 0.7134 | flights | 22.5178\n",
    "| 10 | air | 0.7094 | helicopters | 21.8078"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top k words ranked by cosine function and dot product, as expected, made a lot of sence. By obeserving the result, we can clearly see, that cosine funcion gives more insightufl information in comparison to dot product. Also normalized values of cosine є [-1; 1] are easier to precieve.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-taskB\"></a><h2 style=\"color:rgb(0,120,170)\">Task B: Document Classification with WE (15 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This task follows the same instruction for document classification as provided in Assignment 1. You are indeed free to reuse any part of your code in Assignment 1 for this task. In Assignment 1, the representation of each document was created using a bag of words representation followed by dimensionality reduction. In this task, the document representations are created from the pre-trained word embeddings.\n",
    "\n",
    "**Map word embeddings to dictionary words (5 points).** For every word in the dictionary (as discussed and created in Assignment 1), fetch the corresponding word embedding from the pre-trained model. If no embedding is found, initialize the corresponding word embedding randomly.\n",
    "\n",
    "**Document embedding as the average of word embeddings (5 points).** Using the word embeddings, the representation of each document is defined as the *mean of the vectors of each document's words*. In particular, given the document $d$, consisting of words $\\left[ v_1, v_2, ..., v_{|d|} \\right]$, the document representation $\\mathbf{e}_d$ is defined as:\n",
    "\n",
    "$\\mathbf{e}_d = \\frac{1}{|d|}\\sum_{i=1}^{|d|}{\\mathbf{e}_{v_i}}$\n",
    "\n",
    "where $\\mathbf{e}_{v}$ is the vector of the word $v$, and $|d|$ is the length of the document.\n",
    "\n",
    "**Classification and evaluation (5 points)** Using these new document representations, apply <ins>three classification algorithms</ins> and report the evaluation results (based on accuracy metric) on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-taskC\"></a><h2 style=\"color:rgb(0,120,170)\">Task C: Classification with sent2vec Document Embeddings (2 extra point)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sent2vec [1] suggests another unsupervised approach to creating document embeddings from the underlying word embeddings. First, using the provided code in the paper, train a sendtvec model on the training set to create document embeddings. Then, repeat Task B while using the document embeddings provided by sent2vec. Similar to Task 2, conduct the classification experiments and report evaluation results.\n",
    "\n",
    "[1] M. Pagliardini, P. Gupta, and M. Jaggi. Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features. In Proceedings of the conference of the North American Chapter of the Association for Computational Linguistics (NAACL), 2018.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
